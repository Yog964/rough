<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Hand Gesture Classification</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@latest/dist/teachablemachine-image.min.js"></script>
</head>
<body>
  <h1>Hand Gesture Classification</h1>
  <video id="videoElement" width="640" height="480" autoplay></video>
  <div id="predictionOutput" 
       style="font-size: 240px; color: green; background-color: lightyellow; padding: 10px; margin-top: 10px; width: 500px; border: 1px solid black;">
    Prediction will appear here.
  </div>

  <script>
    const modelURL = "https://raw.githubusercontent.com/Yog964/rough/main/model.json"; // Update with your raw URL
    const gestureLabels = ["Class 1", "Class 2"]; // Update with your class names

    let videoElement = document.getElementById("videoElement");
    let predictionOutput = document.getElementById("predictionOutput");
    let model;

    // Load the model
    async function loadModel() {
      try {
        model = await tf.loadGraphModel(modelURL);
        console.log("Model loaded successfully.");
      } catch (error) {
        console.error("Error loading model:", error);
      }
    }

    // Preprocess the frame
    function preprocessFrame(frame) {
      const tensor = tf.browser.fromPixels(frame);
      const resized = tf.image.resizeBilinear(tensor, [224, 224]);
      const normalized = resized.div(tf.scalar(255.0));
      return normalized.expandDims(0);
    }

    // Capture a frame from the video
    function captureFrame(video) {
      const canvas = document.createElement("canvas");
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      const ctx = canvas.getContext("2d");
      ctx.drawImage(video, 0, 0);
      return canvas;
    }

    // Make predictions
    async function predict() {
      if (!model) {
        console.log("Model not loaded yet.");
        return;
      }

      const frame = captureFrame(videoElement);
      const processedFrame = preprocessFrame(frame);

      const predictions = await model.predict(processedFrame);
      const predictedIndex = predictions.argMax(-1).dataSync()[0];

      predictionOutput.innerText = `Predicted Gesture: ${gestureLabels[predictedIndex]}`;
    }

    // Start the webcam
    async function startWebcam() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        videoElement.srcObject = stream;
        console.log("Webcam started.");
      } catch (error) {
        console.error("Error accessing webcam:", error);
      }
    }

    // Initialize
    async function initialize() {
      await loadModel();
      await startWebcam();

      setInterval(() => {
        predict();
      }, 1000);
    }

    initialize();
  </script>
</body>
</html>
