<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Hand Gesture Classification</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
</head>
<body>
  <h1>Hand Gesture Classification</h1>
  <video id="videoElement" width="640" height="480" autoplay></video>
  <div id="predictionOutput" 
       style="font-size: 24px; 
              color: #fff; 
              background-color: rgba(0, 0, 0, 0.7); 
              padding: 10px; 
              border-radius: 5px; 
              margin-top: 10px; 
              text-align: center;"></div>

  <script>
    const modelURL = "https://teachablemachine.withgoogle.com/models/vqSTbGVX3/"; // Replace YOUR_MODEL_ID

    let videoElement = document.getElementById("videoElement");
    let predictionOutput = document.getElementById("predictionOutput");
    let model; // Declare model globally

    const labels = ["Gesture 1", "Gesture 2"]; // Update with your class labels

    // Load the Teachable Machine model
    async function loadModel() {
      try {
        console.log("Loading model...");
        model = await tf.loadGraphModel(modelURL);
        console.log("Model loaded successfully.");
      } catch (error) {
        console.error("Error loading model:", error);
      }
    }

    // Preprocess the video frame
    function preprocessFrame(frame) {
      const tensor = tf.browser.fromPixels(frame);
      const resized = tf.image.resizeBilinear(tensor, [224, 224]); // Teachable Machine models often use 224x224
      const normalized = resized.div(tf.scalar(255.0));
      return normalized.expandDims(0); // Add batch dimension
    }

    // Capture a frame from the video element
    function captureFrame(video) {
      const canvas = document.createElement("canvas");
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      const ctx = canvas.getContext("2d");
      ctx.drawImage(video, 0, 0);
      return canvas;
    }

    // Make predictions
    async function predict() {
      if (!model) {
        console.warn("Model not loaded yet.");
        return;
      }

      const frame = captureFrame(videoElement);
      const processedFrame = preprocessFrame(frame);
      const prediction = await model.predict(processedFrame).data();
      const predictedIndex = prediction.indexOf(Math.max(...prediction));
      const predictedLabel = labels[predictedIndex];

      predictionOutput.innerText = `Prediction: ${predictedLabel}`;
      console.log("Prediction:", predictedLabel, prediction);
    }

    // Start the webcam
    async function startWebcam() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        videoElement.srcObject = stream;
        console.log("Webcam started.");
      } catch (error) {
        console.error("Error starting webcam:", error);
      }
    }

    // Start the process
    async function start() {
      await loadModel();
      await startWebcam();
      setInterval(predict, 1000); // Make predictions every 1 second
    }

    start();
  </script>
</body>
</html>
